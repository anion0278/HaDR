{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 15:11:58,729 - mmdet - INFO - load model from: torchvision://resnet50\n",
      "2022-03-11 15:11:58,846 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 4, 7, 7]).\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.77s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 15:12:00,104 - mmdet - INFO - load checkpoint from ./checkpoints/epoch_4.pth\n",
      "2022-03-11 15:12:00,468 - mmdet - INFO - Start running, host: Stefan@LAPTOP-UV8365G7, work_dir: c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\checkpoints\n",
      "2022-03-11 15:12:00,468 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"D:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\datasets\\custom.py\", line 131, in __getitem__\n    data = self.prepare_train_img(idx)\n  File \"c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\datasets\\custom.py\", line 144, in prepare_train_img\n    return self.pipeline(results)\n  File \"c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\datasets\\pipelines\\compose.py\", line 24, in __call__\n    data = t(data)\n  File \"c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\datasets\\pipelines\\loading.py\", line 48, in __call__\n    cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA, img)  # inplace\ncv2.error: OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - Layout of the output array dst is incompatible with cv::Mat\n>  - Expected Ptr<cv::UMat> for argument 'dst'\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_360\\634649139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m# try resnext backbone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mtrain_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\apis\\train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[1;34m(model, dataset, cfg, distributed, validate, timestamp)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             timestamp=timestamp)\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\apis\\train.py\u001b[0m in \u001b[0;36m_non_dist_train\u001b[1;34m(model, dataset, cfg, validate, logger, timestamp)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m     \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\mmcv-0.2.16-py3.7-win-amd64.egg\\mmcv\\runner\\runner.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m                         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m                     \u001b[0mepoch_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\mmcv-0.2.16-py3.7-win-amd64.egg\\mmcv\\runner\\runner.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_epochs\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'before_train_epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'before_train_iter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1201\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;31m# instantiate since we don't know how to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: Caught error in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"D:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"D:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"D:\\APPS\\conda\\envs\\solo\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\datasets\\custom.py\", line 131, in __getitem__\n    data = self.prepare_train_img(idx)\n  File \"c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\datasets\\custom.py\", line 144, in prepare_train_img\n    return self.pipeline(results)\n  File \"c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\datasets\\pipelines\\compose.py\", line 24, in __call__\n    data = t(data)\n  File \"c:\\Users\\Stefan\\source\\repos\\HGR_CNN\\SOLO\\mmdet\\datasets\\pipelines\\loading.py\", line 48, in __call__\n    cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA, img)  # inplace\ncv2.error: OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - Layout of the output array dst is incompatible with cv::Mat\n>  - Expected Ptr<cv::UMat> for argument 'dst'\n\n"
     ]
    }
   ],
   "source": [
    "# SOLOv2 train  \n",
    "from importlib import reload\n",
    "\n",
    "\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector, init_detector, inference_detector\n",
    "import os\n",
    "\n",
    "\n",
    "def get_timestamp():\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "\n",
    "cfg = Config.fromfile('./configs/solov2/solov2_light_448_r50_fpn_custom.py') #works, batch size 32\n",
    "cfg.load_from = './checkpoints/epoch_4.pth' #SOLOv2_LIGHT_448_R50_3x \n",
    "# is is possible to dynamically download Pretrained model - the string should start with \"modelzoo://\"\n",
    "\n",
    "# cfg = Config.fromfile('./configs/solov2/solov2_light_512_dcn_r50_fpn_custom.py')\n",
    "# cfg.load_from = './checkpoints/SOLOv2_LIGHT_512_DCN_R50_3x.pth'\n",
    "\n",
    "# cfg = Config.fromfile('./configs/solov2/solov2_light_448_r50_fpn_8gpu_3x.py') #works, batch size 12\n",
    "# cfg.load_from = './checkpoints/SOLOv2_Light_448_R50_3x.pth'\n",
    "\n",
    "cfg.dataset_type = 'CocoDataset'\n",
    "PREFIX = os.path.abspath('G:/datasety/new')\n",
    "cfg.data.train.ann_file = PREFIX + '/instances_hands_30600.json' # single epoch 30k for 26 mins\n",
    "\n",
    "# PREFIX = os.path.abspath('../datasets/rgbd_joined_dataset/ruka_2')\n",
    "# cfg.data.train.ann_file = PREFIX + '/instances_hands_train2022.json'\n",
    "\n",
    "cfg.data.train.img_prefix = PREFIX + \"/color/\"\n",
    "cfg.data.train.type = 'CocoDataset'\n",
    "\n",
    "cfg.optimizer.lr = 0.001\n",
    "cfg.lr_config.warmup = None\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device_ids = range(1)\n",
    "cfg.gpus = 1\n",
    "\n",
    "cfg.work_dir = \"./checkpoints\"\n",
    "cfg.total_epochs = 4\n",
    "cfg.checkpoint_config = dict(create_symlink=False, interval = 1)\n",
    "cfg.data.imgs_per_gpu = 32\n",
    "cfg.data.workers_per_gpu = 4\n",
    "\n",
    "cfg.log_config = dict(\n",
    "    interval=1,\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook'),\n",
    "        dict(type='TensorboardLoggerHook')\n",
    "    ])\n",
    "\n",
    "model = build_detector(cfg.model)\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "datasets[0].CLASSES = [\"hand\", \"dummy\"]\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# CHECK OUT frozen_stages=0 for fine-tunning !!\n",
    "# try resnext backbone\n",
    "\n",
    "train_detector(model, datasets[0], cfg, distributed=False, validate=False)\n",
    "print(\"Training finished\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
